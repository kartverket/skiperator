# Contributing to Skiperator

## Getting started with development

### Installing dependencies

You're going to want to make sure to have the following things installed:

- [Operator SDK](https://sdk.operatorframework.io/docs/building-operators/golang/installation)
- golang
- kubectl
- kustomize
- [kubectx and kubens](https://github.com/ahmetb/kubectx) (Optional)
- docker version 17.03+.
- [kind](https://kind.sigs.k8s.io)
- [istioctl](https://istio.io/latest/docs/setup/install/istioctl/) (Optional)
- wget
- [cert-manager](https://cert-manager.io/docs/installation/) (Optional)

### Running the operator

Check out the project from git. If you want to get to know the project
hierarchy, have a look at the [kubebuilder documentation](https://book.kubebuilder.io/cronjob-tutorial/basic-project.html).

```
$ git clone git@github.com:kartverket/skiperator.git
$ cd skiperator/
```
#### Local setup with make
```
make setup-local
make run-local
```

`make setup-local` will create a kind cluster called `kind-skiperator`, with all dependencies installed.
`make run-local` will build and run the operator. This step can be replaced with building through your IDE if you need debugging.

If for any reason you need a clean local environment, delete your local kind cluster with `kind delete cluster --name skiperator`

#### NOTE: If istio doesnÂ´t load
Allocate more memory to docker with colima(or whatever you are running)
```bash
colima start --cpu 8 --memory 16 --disk 100
```

#### Manual setup
Start a cluster on docker using `kind`.

```
$ kind create cluster
```

Make sure Kind is the active context

```
$ kubectx kind-kind
```

Optionally you may create a new namespace for Skiperator, for example

```
$ kubectl create namespace skiperator-system
$ kubens skiperator-system
```

Install Istio to make sure all CRDs are available

```
$ kubectl create ns istio-gateways && istioctl install
```

Cert-manager (version in link above) must be installed locally on your cluster with

```
$ kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/<VERSION>/cert-manager.yaml
```

Prometheus Operator CRDs must be installed locally:
```
$ kubectl apply -f https://github.com/prometheus-operator/prometheus-operator/releases/download/<VERSION>/stripped-down-crds.yaml
```

Roles and CRDs are autogenerated and can be generated with

```
$ make generate
```

and installed in the cluster with

```
$ kubectl apply -f config/ --recursive
```

A few ConfigMaps for a few settings in Skiperator is needed. These vary from cluster to cluster, but a few dummies have been added in the samples/ folder, together with some sample applications.
These can be added using the following command

```
$ kubectl apply -f samples/ --recursive
```

To start `skiperator` locally on your computer, you can use the the make target `run-local`
which will generate CRD's, apply them in your local kind-cluster, build and run skiperator.
The default `kubectl` context is `kind-kind`. To override, set the env-variable `SKIPERATOR_CONTEXT`
to the name of the desired context.

```
$ make run-local
```

Now you should have a running app in your namespace. Run the following command
to see all the created resources.

```
$ kubectl get Application,all,networkpolicies,PeerAuthentication,Gateway,VirtualService,Sidecar
```

Changes to the api requires the CRD to be generated and applied again, and changes to the application controllers requires skiperator to be rebuilt and startet again.

Use the command `make run-local` to do this in a safe way without mixing up kubectl contexts.

## Tests
This project is using [Chainsaw](https://github.com/kyverno/chainsaw/) for testing.     

To run tests against your running kind cluster, with skiperator running in your IDE:
```shell
# All tests
make test

# Single test
make test-single dir=tests/application/hpa
```

If you want to run tests without running skiperator yourself you can use
```shell
# All tests
make run-test

# Single test
make run-test TEST_DIR=tests/application/hpa
```

You can find more handy parameters [here](https://kyverno.github.io/chainsaw/latest/commands/chainsaw_test/).
### Known issues
Parallel tests can cause some concurrency issues. Try lowering the amount of tests running in parallel if you experience tests that occasionally fail.
Concurrent tests means a unique namespace for each test. Chainsaw will create a unique namespace, but in some cases 
you might need to specify a namespace. In that case name your namespace <testname>-ns so we dont get overlapping namespaces.

## Writing code

Have a look at the following files:

- The main logic is found in the controllers, which are split for their respective resources https://github.com/kartverket/skiperator/blob/main/controllers
- The `Application` Custom Resource API is found in https://github.com/kartverket/skiperator/blob/main/api/v1alpha1/application.go
- A very simple example `Application` that can be applied to the cluster is found in https://github.com/kartverket/skiperator/tree/main/samples/

Also look at the following documentation pages:

- https://sdk.operatorframework.io/docs/building-operators/golang/tutorial
- https://sdk.operatorframework.io/docs/building-operators/golang/references/client/
